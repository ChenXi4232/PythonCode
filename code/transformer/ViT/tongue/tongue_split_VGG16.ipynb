{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['_background_', 'Tg']\n",
      "torch.Size([3, 1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "tensor([0., 1.])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "class TongueDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_dir = os.path.join(root_dir, 'images')\n",
    "        self.mask_dir = os.path.join(root_dir, 'annotations')\n",
    "        self.class_names = self.load_class_names()\n",
    "\n",
    "    def load_class_names(self):\n",
    "        class_names_file = os.path.join(self.root_dir, 'class_names.txt')\n",
    "        with open(class_names_file, 'r') as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [name.strip() for name in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.image_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.listdir(self.image_dir)[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(\n",
    "            self.mask_dir, os.path.splitext(img_name)[0] + '.png')\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = transforms.Resize((1000, 1000))(mask)\n",
    "            mask = torch.tensor(np.array(mask), dtype=torch.float32)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((1000, 1000)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = TongueDataset(root_dir='./data/split_dataset_ultra', transform=data_transform)\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset.class_names)\n",
    "print(dataset[0][0].shape)\n",
    "print(dataset[0][1].shape)\n",
    "print(dataset[0][1].unique())\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1000, 1000]) torch.Size([2, 1000, 1000])\n",
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomApply(transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                           saturation=0.2, hue=0.1)),\n",
    "    transforms.RandomApply(transforms.GaussianBlur(3, sigma=(0.1, 2.0)), 0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                             0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                             0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 划分数据集\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "train_dataloader.dataset.transform = aug_transform\n",
    "for i, (img, mask) in enumerate(train_dataloader):\n",
    "    print(img.shape, mask.shape)\n",
    "    print(mask.unique())\n",
    "    break\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "val_dataloader.dataset.transform = transform\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "test_dataloader.dataset.transform = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 定义基于VGG16的FCN网络\n",
    "class VGG16_FCN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG16_FCN, self).__init__()\n",
    "        # 加载预训练的VGG16模型\n",
    "        vgg16 = models.vgg16(\n",
    "            weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "        # 取出VGG16的前面部分（去掉全连接层）\n",
    "        self.features = vgg16.features\n",
    "\n",
    "        # 用1x1卷积替换VGG16的全连接层\n",
    "        self.conv6 = nn.Conv2d(512, 4096, kernel_size=5, padding=2)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout2d()\n",
    "        self.conv7 = nn.Conv2d(4096, 4096, kernel_size=3, padding=1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout2d()\n",
    "\n",
    "        # 最后的卷积层用于生成分割结果\n",
    "        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        self.upscore = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, kernel_size=64, stride=32, padding=16, bias=False)\n",
    "\n",
    "        # 初始化上采样层权重\n",
    "        self.upscore.weight.data.fill_(0)\n",
    "        self.upscore.weight.data[:, :, 16, 16] = 1  # 双线性插值\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        x = self.features(x)\n",
    "        x = self.relu6(self.conv6(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = self.relu7(self.conv7(x))\n",
    "        x = self.dropout7(x)\n",
    "        x = self.score_fr(x)\n",
    "        x = self.upscore(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def convert_to_one_hot(labels):\n",
    "    # 获取原始标签中的类别数\n",
    "    num_classes = len(torch.unique(labels))\n",
    "\n",
    "    # 创建一个大小为 (B, C, W, H) 的零张量，其中 C 是类别数\n",
    "    one_hot_labels = torch.zeros(labels.size(\n",
    "        0), num_classes, *labels.size()[1:])\n",
    "\n",
    "    # 遍历每个样本的原始标签，并将相应位置的值设置为 1\n",
    "    for i in range(num_classes):\n",
    "        one_hot_labels[:, i, :, :] = (labels == i).float()\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "class SegmentationLoss(nn.Module):\n",
    "    def __init__(self, weight_bce=0.5, weight_connectivity=0, weight_smoothness=0):\n",
    "        super(SegmentationLoss, self).__init__()\n",
    "        self.weight_bce = weight_bce\n",
    "        self.weight_connectivity = weight_connectivity\n",
    "        self.weight_smoothness = weight_smoothness\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.smooth = 1e-6\n",
    "\n",
    "    def forward(self, logits, masks):\n",
    "        # 计算 BCE Loss\n",
    "        bce_loss = self.bce_loss(logits, masks)\n",
    "\n",
    "        # 计算 Dice Loss\n",
    "        probs = torch.sigmoid(logits)\n",
    "        intersection = torch.sum(probs * masks)\n",
    "        dice_loss = 1 - (2. * intersection + self.smooth) / \\\n",
    "            (torch.sum(probs) + torch.sum(masks) + self.smooth)\n",
    "        # 计算连通性损失\n",
    "        connectivity_loss = 0\n",
    "        if self.weight_connectivity > 0:\n",
    "            connectivity_loss = self.connectivity_loss(logits)\n",
    "\n",
    "        # 计算平滑性损失\n",
    "        smoothness_loss = 0\n",
    "        if self.weight_smoothness > 0:\n",
    "            smoothness_loss = self.smoothness_loss(logits)\n",
    "\n",
    "        # 加权结合损失\n",
    "        combined_loss = self.weight_bce * bce_loss + \\\n",
    "            (1 - self.weight_bce) * dice_loss + \\\n",
    "            self.weight_connectivity * connectivity_loss + \\\n",
    "            self.weight_smoothness * smoothness_loss\n",
    "\n",
    "        return combined_loss\n",
    "\n",
    "    # 连通性损失函数\n",
    "    def connectivity_loss(self, mask):\n",
    "        class_indices = torch.tensor(torch.argmax(\n",
    "            mask, dim=1, keepdim=True), dtype=torch.float32).to(device)\n",
    "        connected_components = torch.unique(class_indices)\n",
    "        count = 0\n",
    "        for value in connected_components:\n",
    "            binary_mask = (class_indices == value).float()\n",
    "            _, labels = binary_mask.view(1, -1).unique(dim=1, return_inverse=True)\n",
    "            count += labels.max().item() + 1\n",
    "        loss = count - 1\n",
    "        return loss\n",
    "\n",
    "    # 平滑性损失函数\n",
    "    def smoothness_loss(self, mask):\n",
    "        class_indices = torch.tensor(torch.argmax(\n",
    "            mask, dim=1, keepdim=True), dtype=torch.float32).to(device)\n",
    "        sobel_x = torch.abs(F.conv2d(class_indices, torch.tensor(\n",
    "            [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device='cuda').unsqueeze(0).unsqueeze(0)))\n",
    "        sobel_y = torch.abs(F.conv2d(class_indices, torch.tensor(\n",
    "            [[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device='cuda').unsqueeze(0).unsqueeze(0)))\n",
    "        edge_curvature = torch.mean(sobel_x + sobel_y)\n",
    "        loss = edge_curvature\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练模型\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                criterion = SegmentationLoss()\n",
    "            elif i == 1:\n",
    "                criterion = SegmentationLoss(weight_connectivity=2)\n",
    "            else:\n",
    "                criterion = SegmentationLoss(weight_smoothness=2)\n",
    "            for images, labels in tqdm(train_loader):\n",
    "                images = images.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                # print(outputs.size())\n",
    "                outputs_resized = F.interpolate(outputs, size=(images.size(\n",
    "                    2), images.size(3)), mode='bilinear', align_corners=True)\n",
    "                labels_for_loss = convert_to_one_hot(labels).to(device)\n",
    "                loss = criterion(outputs_resized, labels_for_loss)  # 根据需要定义损失函数\n",
    "                # loss = criterion(outputs, labels_for_loss)\n",
    "                loss.backward()\n",
    "                # if i == 2:\n",
    "                train_running_loss += loss.item()\n",
    "                optimizer.step()\n",
    "    \n",
    "            # 打印每个epoch的损失\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_running_loss/len(train_loader)}\")\n",
    "            # torch.save(model.state_dict(), f'vgg16_fcn_{epoch+1}_{i+1}.pth')\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        IOU = 0\n",
    "        iou_class1 = 0\n",
    "        iou_class2 = 0\n",
    "        criterion = SegmentationLoss()\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "            outputs_resized = F.interpolate(outputs, size=(images.size(\n",
    "                2), images.size(3)), mode='bilinear', align_corners=True)\n",
    "            one_hot_labels = convert_to_one_hot(labels).to(device)\n",
    "            loss = criterion(outputs_resized, one_hot_labels)\n",
    "            # loss = criterion(outputs, labels_for_loss)\n",
    "            val_running_loss += loss.item()\n",
    "            outputs = torch.sigmoid(outputs_resized)  # 使用sigmoid函数将输出限制在0到1之间\n",
    "\n",
    "            # 分别取出两个类别的输出和标签\n",
    "            outputs_class1 = outputs[:, 0, :, :]  # 第一个类别的输出\n",
    "            outputs_class2 = outputs[:, 1, :, :]  # 第二个类别的输出\n",
    "            labels_class1 = one_hot_labels[:, 0, :, :]    # 第一个类别的标签\n",
    "            labels_class2 = one_hot_labels[:, 1, :, :]    # 第二个类别的标签\n",
    "\n",
    "            # 计算第一个类别的交并比（IOU）\n",
    "            intersection_class1 = torch.sum(outputs_class1 * labels_class1)\n",
    "            union_class1 = torch.sum(outputs_class1) + torch.sum(labels_class1)\n",
    "            temp_iou1 = (intersection_class1 + 1e-6) / (union_class1 - intersection_class1 + 1e-6)\n",
    "            iou_class1 += temp_iou1\n",
    "\n",
    "            # 计算第二个类别的交并比（IOU）\n",
    "            intersection_class2 = torch.sum(outputs_class2 * labels_class2)\n",
    "            union_class2 = torch.sum(outputs_class2) + torch.sum(labels_class2)\n",
    "            temp_iou2 = (intersection_class2 + 1e-6) / (union_class2 - intersection_class2 + 1e-6)\n",
    "            iou_class2 += temp_iou2\n",
    "\n",
    "            # 计算平均IOU\n",
    "            IOU += (temp_iou1 + temp_iou2) / 2\n",
    "\n",
    "            # 输出遮罩\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            mask1 = outputs[0].squeeze().cpu().numpy()\n",
    "            final_mask1 = np.zeros_like(mask1)\n",
    "            final_mask1[mask1 == 1] = 255\n",
    "            final_mask1 = Image.fromarray(final_mask1.astype(np.uint8))\n",
    "            final_mask1.save('mask1.png')\n",
    "            label_mask1 = labels[0].squeeze().cpu().numpy()\n",
    "            final_label_mask1 = np.zeros_like(label_mask1)\n",
    "            final_label_mask1[label_mask1 == 1] = 255\n",
    "            final_label_mask1 = Image.fromarray(final_label_mask1.astype(np.uint8))\n",
    "            final_label_mask1.save('label_mask1.png')\n",
    "            mask2 = outputs[1].squeeze().cpu().numpy()\n",
    "            final_mask2 = np.zeros_like(mask2)\n",
    "            final_mask2[mask2 == 1] = 255\n",
    "            final_mask2 = Image.fromarray(final_mask2.astype(np.uint8))\n",
    "            final_mask2.save('mask2.png')\n",
    "            label_mask2 = labels[1].squeeze().cpu().numpy()\n",
    "            final_label_mask2 = np.zeros_like(label_mask2)\n",
    "            final_label_mask2[label_mask2 == 1] = 255\n",
    "            final_label_mask2 = Image.fromarray(final_label_mask2.astype(np.uint8))\n",
    "            final_label_mask2.save('label_mask2.png')\n",
    "\n",
    "        \n",
    "        print(\n",
    "            f\"Validation Loss: {val_running_loss/len(val_loader)}, mIOU: {IOU/len(val_loader)}, IOU Background: {iou_class1/len(val_loader)}, IOU Tongue: {iou_class2/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [06:24<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.15614316184694568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]C:\\Users\\ChenXi\\AppData\\Local\\Temp\\ipykernel_20172\\2254088095.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_indices = torch.tensor(torch.argmax(\n",
      "100%|██████████| 300/300 [06:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.2018163971044125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]C:\\Users\\ChenXi\\AppData\\Local\\Temp\\ipykernel_20172\\2254088095.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_indices = torch.tensor(torch.argmax(\n",
      "100%|██████████| 300/300 [05:04<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.269814861584455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.025639284355565905, mIOU: 0.94784015417099, IOU Background: 0.9738190770149231, IOU Tongue: 0.9218613505363464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:06<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.022381475743216774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 6.033679944650891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:05<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 6.089551434946867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016394456662237645, mIOU: 0.9663571119308472, IOU Background: 0.9835390448570251, IOU Tongue: 0.9491748809814453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.025447364879461625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:19<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 6.038619524074408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:20<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 6.08311036701159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.007345855028834194, mIOU: 0.9862232804298401, IOU Background: 0.9932237863540649, IOU Tongue: 0.9792233109474182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:03<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.006819150667482366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:50<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 6.01509184302995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [06:18<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 6.07816922235225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:39<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.021899611265398564, mIOU: 0.965167224407196, IOU Background: 0.982033371925354, IOU Tongue: 0.9483011364936829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [06:10<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.011047916888880233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:24<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 6.018418585935918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:03<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 6.058987837537813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:12<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0073505320237018165, mIOU: 0.9870427250862122, IOU Background: 0.9935647249221802, IOU Tongue: 0.9805207848548889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:00<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.005762331720131139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:04<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 6.011235408222613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:00<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 6.050891201947816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.006209837822243571, mIOU: 0.9890509843826294, IOU Background: 0.9946458339691162, IOU Tongue: 0.9834563136100769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:32<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.00481397620945548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:16<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 6.009516108752384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 6.0486799290427005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.005712169385515153, mIOU: 0.9904630184173584, IOU Background: 0.9952514171600342, IOU Tongue: 0.9856749773025513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:58<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.004458037110355993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 6.058027822864242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:03<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 6.127323911051887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.010523166446946562, mIOU: 0.9818862676620483, IOU Background: 0.9909308552742004, IOU Tongue: 0.9728416800498962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.009229930222500116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:54<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 6.018838938057888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:44<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 6.059588197897344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.006989772343076766, mIOU: 0.9877044558525085, IOU Background: 0.9939173460006714, IOU Tongue: 0.9814914464950562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/300 [00:49<04:18,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "num_classes = 2  # Background and tongue\n",
    "model = VGG16_FCN(num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dataloader, val_dataloader, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 定义基于VGG16的FCN网络\n",
    "class VGG16_FCN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG16_FCN, self).__init__()\n",
    "        # 加载预训练的VGG16模型\n",
    "        vgg16 = models.vgg16(\n",
    "            weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "        # 取出VGG16的前面部分（去掉全连接层）\n",
    "        self.features = vgg16.features\n",
    "\n",
    "        # 用1x1卷积替换VGG16的全连接层\n",
    "        self.conv6 = nn.Conv2d(512, 4096, kernel_size=1)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout2d()\n",
    "        self.conv7 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout2d()\n",
    "\n",
    "        # 最后的卷积层用于生成分割结果\n",
    "        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        self.upscore = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, kernel_size=64, stride=32, padding=16, bias=False)\n",
    "\n",
    "        # 初始化上采样层权重\n",
    "        self.upscore.weight.data.fill_(0)\n",
    "        self.upscore.weight.data[:, :, 16, 16] = 1  # 双线性插值\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        x = self.features(x)\n",
    "        x = self.relu6(self.conv6(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = self.relu7(self.conv7(x))\n",
    "        x = self.dropout7(x)\n",
    "        x = self.score_fr(x)\n",
    "        x = self.upscore(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "def get_segmentation_mask(model, image_path):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                             0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    print(image.size())\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    output = torch.sigmoid(output)\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    mask = output.squeeze().cpu().numpy()\n",
    "    return mask\n",
    "\n",
    "# Get segmentation mask for a sample image\n",
    "\n",
    "image_path = './data/test/label_data/test1.jpg'  # Replace with your image path\n",
    "# 载入模型权重\n",
    "model = VGG16_FCN(num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "mask = get_segmentation_mask(model, image_path)\n",
    "\n",
    "\n",
    "# Create the final mask where tongue region is white and background is black\n",
    "\n",
    "final_mask = np.zeros_like(mask)\n",
    "\n",
    "final_mask[mask == 0] = 255\n",
    "final_mask = Image.fromarray(final_mask.astype(np.uint8))\n",
    "\n",
    "# 叠加原图\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize(final_mask.size)\n",
    "image.paste(final_mask, (0, 0), final_mask)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.12864163 0.33627678 0.32833279]\n",
      "   [0.48987763 0.58399996 0.01479922]\n",
      "   [0.2404101  0.11303117 0.55008898]]\n",
      "\n",
      "  [[0.63509489 0.93711281 0.04018763]\n",
      "   [0.15410985 0.4658085  0.61758847]\n",
      "   [0.79034205 0.93190566 0.43294675]]]\n",
      "\n",
      "\n",
      " [[[0.06077017 0.07451507 0.1792317 ]\n",
      "   [0.86664552 0.00749065 0.53963023]\n",
      "   [0.90220283 0.50632795 0.3555912 ]]\n",
      "\n",
      "  [[0.58280628 0.51122657 0.54808611]\n",
      "   [0.18869061 0.99385473 0.57085092]\n",
      "   [0.98435916 0.46737864 0.85101047]]]]\n",
      "tensor([[[[0.5321, 0.5833, 0.5814],\n",
      "          [0.6201, 0.6420, 0.5037],\n",
      "          [0.5598, 0.5282, 0.6342]],\n",
      "\n",
      "         [[0.6536, 0.7185, 0.5100],\n",
      "          [0.5385, 0.6144, 0.6497],\n",
      "          [0.6879, 0.7175, 0.6066]]],\n",
      "\n",
      "\n",
      "        [[[0.5152, 0.5186, 0.5447],\n",
      "          [0.7040, 0.5019, 0.6317],\n",
      "          [0.7114, 0.6239, 0.5880]],\n",
      "\n",
      "         [[0.6417, 0.6251, 0.6337],\n",
      "          [0.5470, 0.7298, 0.6390],\n",
      "          [0.7280, 0.6148, 0.7008]]]])\n",
      "tensor([[[[0.3760, 0.3542, 0.5715],\n",
      "          [0.5832, 0.5295, 0.3537],\n",
      "          [0.3659, 0.3060, 0.5293]],\n",
      "\n",
      "         [[0.6240, 0.6458, 0.4285],\n",
      "          [0.4168, 0.4705, 0.6463],\n",
      "          [0.6341, 0.6940, 0.4707]]],\n",
      "\n",
      "\n",
      "        [[[0.3724, 0.3925, 0.4088],\n",
      "          [0.6633, 0.2716, 0.4922],\n",
      "          [0.4795, 0.5097, 0.3786]],\n",
      "\n",
      "         [[0.6276, 0.6075, 0.5912],\n",
      "          [0.3367, 0.7284, 0.5078],\n",
      "          [0.5205, 0.4903, 0.6214]]]])\n",
      "tensor([[[[1, 1, 0],\n",
      "          [0, 0, 1],\n",
      "          [1, 1, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1],\n",
      "          [0, 1, 1],\n",
      "          [1, 0, 1]]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 生成随机的形状为 (2, 2, 3, 3) 的张量，值在 0 到 1 之间\n",
    "random_tensor = np.random.rand(2, 2, 3, 3)\n",
    "\n",
    "print(random_tensor)\n",
    "\n",
    "# 将 NumPy 数组转换为 PyTorch 张量\n",
    "random_tensor = torch.tensor(random_tensor, dtype=torch.float32)\n",
    "print(torch.sigmoid(random_tensor))\n",
    "print(torch.softmax(random_tensor, dim=1))\n",
    "print(torch.argmax(random_tensor, dim=1, keepdim=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2.2.1_11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
